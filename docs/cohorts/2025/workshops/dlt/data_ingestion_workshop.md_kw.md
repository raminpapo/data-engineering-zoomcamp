# Keywords: data_ingestion_workshop.md

**File**: `cohorts/2025/workshops/dlt/data_ingestion_workshop.md`

## Keyword Index

### APIs

- **Defined in**: [cohorts/2025/workshops/dlt/data_ingestion_workshop.md](./data_ingestion_workshop.md_docs.md)
- **Context**: ✅ **Extracting** data from various sources (APIs, databases, files).

### Event

- **Defined in**: [cohorts/2025/workshops/dlt/data_ingestion_workshop.md](./data_ingestion_workshop.md_docs.md)
- **Context**: The collected data flows into an event queue, where it’s organized and prepared for the

### PageNumberPaginator

- **Defined in**: [cohorts/2025/workshops/dlt/data_ingestion_workshop.md](./data_ingestion_workshop.md_docs.md)
- **Context**: dlt.sources.helpers.rest_client.paginators import PageNumberPaginator

### RESTClient

- **Defined in**: [cohorts/2025/workshops/dlt/data_ingestion_workshop.md](./data_ingestion_workshop.md_docs.md)
- **Context**: lly writing pagination logic, let’s use **dlt’s [`RESTClient` helper](https://dlthub.com/docs/genera...

### Sara

- **Defined in**: [cohorts/2025/workshops/dlt/data_ingestion_workshop.md](./data_ingestion_workshop.md_docs.md)
- **Context**: * [Data ingestion with DLT to Bigquery from Sara Sabater](https://github.com/saraisab/Data_Enginee

### Webhooks

- **Defined in**: [cohorts/2025/workshops/dlt/data_ingestion_workshop.md](./data_ingestion_workshop.md_docs.md)
- **Context**: - from Webhooks to event queues;

### breaking

- **Defined in**: [cohorts/2025/workshops/dlt/data_ingestion_workshop.md](./data_ingestion_workshop.md_docs.md)
- **Context**: ider on extraction, to prevent the pipelines from breaking, and to keep them running smoothly:

### business

- **Defined in**: [cohorts/2025/workshops/dlt/data_ingestion_workshop.md](./data_ingestion_workshop.md_docs.md)
- **Context**: - **RESTful APIs**: Provide records of data from business applications.

### collection

- **Defined in**: [cohorts/2025/workshops/dlt/data_ingestion_workshop.md](./data_ingestion_workshop.md_docs.md)
- **Context**: ically manage the entire **data lifecycle**, from collection to consumption.

### crashing

- **Defined in**: [cohorts/2025/workshops/dlt/data_ingestion_workshop.md](./data_ingestion_workshop.md_docs.md)
- **Context**: To prevent your pipeline from crashing, you need to control memory usage.

### dlt

- **Defined in**: [cohorts/2025/workshops/dlt/data_ingestion_workshop.md](./data_ingestion_workshop.md_docs.md)
- **Context**: # Data ingestion with dlt

### duckdb

- **Defined in**: [cohorts/2025/workshops/dlt/data_ingestion_workshop.md](./data_ingestion_workshop.md_docs.md)
- **Context**: /dlthub.com/docs/reference/installation) dlt with DuckDB as destination:

### google

- **Defined in**: [cohorts/2025/workshops/dlt/data_ingestion_workshop.md](./data_ingestion_workshop.md_docs.md)
- **Context**: uery, Snowflake, Redshift)** or **data lakes (S3, Google Cloud Storage, Parquet files)** in dlt is i...

### its

- **Defined in**: [cohorts/2025/workshops/dlt/data_ingestion_workshop.md](./data_ingestion_workshop.md_docs.md)
- **Context**: They ensure data flows seamlessly from its source to its final destination, where it can dri

### local

- **Defined in**: [cohorts/2025/workshops/dlt/data_ingestion_workshop.md](./data_ingestion_workshop.md_docs.md)
- **Context**: - from APIs to local files;

### nested

- **Defined in**: [cohorts/2025/workshops/dlt/data_ingestion_workshop.md](./data_ingestion_workshop.md_docs.md)
- **Context**: s: CSV, JSON, where fields might be inconsistent, nested or missing key details.

### ny_taxi

- **Defined in**: [cohorts/2025/workshops/dlt/data_ingestion_workshop.md](./data_ingestion_workshop.md_docs.md)
- **Context**: def ny_taxi():

### our

- **Defined in**: [cohorts/2025/workshops/dlt/data_ingestion_workshop.md](./data_ingestion_workshop.md_docs.md)
- **Context**: Here’s how we design our requester:

### page

- **Defined in**: [cohorts/2025/workshops/dlt/data_ingestion_workshop.md](./data_ingestion_workshop.md_docs.md)
- **Context**: amiliar with. The API returns **1,000 records per page**, and we must request multiple pages to retr...

### paginated_getter

- **Defined in**: [cohorts/2025/workshops/dlt/data_ingestion_workshop.md](./data_ingestion_workshop.md_docs.md)
- **Context**: def paginated_getter():

### requests

- **Defined in**: [cohorts/2025/workshops/dlt/data_ingestion_workshop.md](./data_ingestion_workshop.md_docs.md)
- **Context**: rate limits**: APIs often restrict the number of requests you can make in a given time.

### userdata

- **Defined in**: [cohorts/2025/workshops/dlt/data_ingestion_workshop.md](./data_ingestion_workshop.md_docs.md)
- **Context**: from google.colab import userdata

### various

- **Defined in**: [cohorts/2025/workshops/dlt/data_ingestion_workshop.md](./data_ingestion_workshop.md_docs.md)
- **Context**: ✅ **Extracting** data from various sources (APIs, databases, files).


---
*Total keywords: 23*
