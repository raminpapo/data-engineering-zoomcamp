# Keywords: aggregation_job.py

**File**: `06-streaming/pyflink/src/job/aggregation_job.py`

## Keyword Index

### Duration

- **Defined in**: [06-streaming/pyflink/src/job/aggregation_job.py](./aggregation_job.py_docs.md)
- **Context**: from pyflink.common.time import Duration

### EnvironmentSettings

- **Defined in**: [06-streaming/pyflink/src/job/aggregation_job.py](./aggregation_job.py_docs.md)
- **Context**: from pyflink.table import EnvironmentSettings, DataTypes, TableEnvironment, StreamTableEnvironm

### Kafka

- **Defined in**: [06-streaming/pyflink/src/job/aggregation_job.py](./aggregation_job.py_docs.md)
- **Context**: 'connector' = 'kafka',

### StreamExecutionEnvironment

- **Defined in**: [06-streaming/pyflink/src/job/aggregation_job.py](./aggregation_job.py_docs.md)
- **Context**: from pyflink.datastream import StreamExecutionEnvironment

### WatermarkStrategy

- **Defined in**: [06-streaming/pyflink/src/job/aggregation_job.py](./aggregation_job.py_docs.md)
- **Context**: from pyflink.common.watermark_strategy import WatermarkStrategy

### create_events_aggregated_sink

- **Defined in**: [06-streaming/pyflink/src/job/aggregation_job.py](./aggregation_job.py_docs.md)
- **Context**: def create_events_aggregated_sink(t_env):

### create_events_source_kafka

- **Defined in**: [06-streaming/pyflink/src/job/aggregation_job.py](./aggregation_job.py_docs.md)
- **Context**: def create_events_source_kafka(t_env):

### log_aggregation

- **Defined in**: [06-streaming/pyflink/src/job/aggregation_job.py](./aggregation_job.py_docs.md)
- **Context**: def log_aggregation():

### pyflink

- **Defined in**: [06-streaming/pyflink/src/job/aggregation_job.py](./aggregation_job.py_docs.md)
- **Context**: from pyflink.datastream import StreamExecutionEnvironment


---
*Total keywords: 9*
