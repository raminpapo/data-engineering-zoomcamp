# Documentation: consumer.py

## File Metadata

- **Path**: `06-streaming/python/redpanda_example/consumer.py`
- **Size**: 1,943 bytes
- **Lines**: 48
- **Extension**: `.py`
- **Last Modified**: 2025-11-15T19:46:38.183125

## Original Source

```python
import os
from typing import Dict, List
from json import loads
from kafka import KafkaConsumer

from ride import Ride
from settings import BOOTSTRAP_SERVERS, KAFKA_TOPIC


class JsonConsumer:
    def __init__(self, props: Dict):
        self.consumer = KafkaConsumer(**props)

    def consume_from_kafka(self, topics: List[str]):
        self.consumer.subscribe(topics)
        print('Consuming from Kafka started')
        print('Available topics to consume: ', self.consumer.subscription())
        while True:
            try:
                # SIGINT can't be handled when polling, limit timeout to 1 second.
                message = self.consumer.poll(1.0)
                if message is None or message == {}:
                    continue
                for message_key, message_value in message.items():
                    for msg_val in message_value:
                        print(msg_val.key, msg_val.value)
            except KeyboardInterrupt:
                break

        self.consumer.close()


if __name__ == '__main__':
    config = {
        'bootstrap_servers': BOOTSTRAP_SERVERS,
        'auto_offset_reset': 'earliest',
        'enable_auto_commit': True,
        'key_deserializer': lambda key: int(key.decode('utf-8')),
        'value_deserializer': lambda x: loads(x.decode('utf-8'), object_hook=lambda d: Ride.from_dict(d)),
        'group_id': 'consumer.group.id.json-example.1',
    }

    json_consumer = JsonConsumer(props=config)
    json_consumer.consume_from_kafka(topics=[KAFKA_TOPIC])


# There's no schema in JSON format, so if the schema changes and one column is removed or new one added or the data types is changed, the Ride class would still work and produce-consume messages would still run without a hitch.
# But the issue is in the downstream Analytics as the dataset would no longer have that column and the dashboards would thus fail. Therefore, the trust in our data and processes would erodes.
```

## High-Level Overview

Python module containing 2 functions and 2 classes.

## Detailed Analysis

### Functions
- **`__init__(self, props: Dict)`**
- **`consume_from_kafka(self, topics: List[str])`**

### Classes
- **`JsonConsumer`**

### Dependencies
- `os`
- `Dict, List`
- `loads`
- `KafkaConsumer`
- `Ride`
- `BOOTSTRAP_SERVERS, KAFKA_TOPIC`


## Usage & Examples

*Examples found in source code - see original source above.*


## Dependencies & Related Files

### Imported Modules

- `loads`
- `kafka`
- `os`
- `settings`
- `ride`
- `Dict`
- `json`
- `Ride`
- `KafkaConsumer`
- `typing`
- `BOOTSTRAP_SERVERS`


## Performance & Security Notes

*No specific performance or security issues detected.*


## Testing & Validation

*No test framework detected. Manual testing may be required.*


---
*Generated by Repo Book Generator v1.0.0*
