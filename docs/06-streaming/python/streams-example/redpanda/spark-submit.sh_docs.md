# Documentation: spark-submit.sh

## File Metadata

- **Path**: `06-streaming/python/streams-example/redpanda/spark-submit.sh`
- **Size**: 582 bytes
- **Lines**: 21
- **Extension**: `.sh`
- **Last Modified**: 2025-11-15T19:46:38.192125

## Original Source

```bash
# Submit Python code to SparkMaster

if [ $# -lt 1 ]
then
	echo "Usage: $0 <pyspark-job.py> [ executor-memory ]"
	echo "(specify memory in string format such as \"512M\" or \"2G\")"
	exit 1
fi
PYTHON_JOB=$1

if [ -z $2 ]
then
	EXEC_MEM="1G"
else
	EXEC_MEM=$2
fi
spark-submit --master spark://localhost:7077 --num-executors 2 \
	           --executor-memory $EXEC_MEM --executor-cores 1 \
             --packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.1,org.apache.spark:spark-avro_2.12:3.5.1,org.apache.spark:spark-streaming-kafka-0-10_2.12:3.5.1 \
             $PYTHON_JOB

```

## High-Level Overview

SH file with 21 lines.

## Detailed Analysis

*Detailed analysis not available for this file type.*


## Usage & Examples

*Examples found in source code - see original source above.*


## Dependencies & Related Files

*No external dependencies detected.*


## Performance & Security Notes

*No specific performance or security issues detected.*


## Testing & Validation

*No test framework detected. Manual testing may be required.*


---
*Generated by Repo Book Generator v1.0.0*
