# Documentation: README.md

## File Metadata

- **Path**: `06-streaming/python/README.md`
- **Size**: 1,020 bytes
- **Lines**: 32
- **Extension**: `.md`
- **Last Modified**: 2025-11-15T19:46:38.177125

## Original Source

```markdown
### Stream-Processing with Python

In this document, you will be finding information about stream processing 
using different Python libraries (`kafka-python`,`confluent-kafka`,`pyspark`, `faust`).

This Python module can be separated in following modules.

####  1. Docker
Docker module includes, Dockerfiles and docker-compose definitions 
to run Kafka and Spark in a docker container. Setting up required services is
the prerequsite step for running following modules.

#### 2. Kafka Producer - Consumer Examples
- [Json Producer-Consumer Example](json_example) using `kafka-python` library
- [Avro Producer-Consumer Example](avro_example) using `confluent-kafka` library

Both of these examples require, up-and running Kafka services, therefore please ensure
following steps under [docker-README](docker/README.md)

To run the producer-consumer examples in the respective example folder, run following commands
```bash
# Start producer script
python3 producer.py
# Start consumer script
python3 consumer.py
```






```

## High-Level Overview

Markdown documentation file.

## Detailed Analysis

*Detailed analysis not available for this file type.*


## Usage & Examples

*Examples found in source code - see original source above.*


## Dependencies & Related Files

*No external dependencies detected.*


## Performance & Security Notes

*No specific performance or security issues detected.*


## Testing & Validation

*No test framework detected. Manual testing may be required.*


---
*Generated by Repo Book Generator v1.0.0*
